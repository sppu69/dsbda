{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80442b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042816c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\aarad\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\aarad\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\aarad\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\aarad\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aarad\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\aarad\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d32fe51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2893ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f36997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1d4f260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PhraseId', 'SentenceId', 'Phrase', 'Sentiment'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "017fd754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId      0\n",
       "SentenceId    0\n",
       "Phrase        0\n",
       "Sentiment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5efdf6",
   "metadata": {},
   "source": [
    "## Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1731b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Phrase'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eca29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aarad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [A, series, of, escapades, demonstrating, the,...\n",
       "1    [A, series, of, escapades, demonstrating, the,...\n",
       "2                                          [A, series]\n",
       "3                                                  [A]\n",
       "4                                             [series]\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Required download \n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8542572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0258243a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [A, series, of, escapades, demonstrating, the,...\n",
       "1    [A, series, of, escapades, demonstrating, the,...\n",
       "2                                          [A, series]\n",
       "3                                                  [A]\n",
       "4                                             [series]\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df['Phrase'].apply(word_tokenize)\n",
    "df['tokens'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07399ff",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab290613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\aarad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c31c714e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>[A, series, of, escapades, demonstrating, the,...</td>\n",
       "      <td>[(A, DT), (series, NN), (of, IN), (escapades, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>[A, series, of, escapades, demonstrating, the,...</td>\n",
       "      <td>[(A, DT), (series, NN), (of, IN), (escapades, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series</td>\n",
       "      <td>[A, series]</td>\n",
       "      <td>[(A, DT), (series, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[(A, DT)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[(series, NN)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Phrase  \\\n",
       "0  A series of escapades demonstrating the adage ...   \n",
       "1  A series of escapades demonstrating the adage ...   \n",
       "2                                           A series   \n",
       "3                                                  A   \n",
       "4                                             series   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [A, series, of, escapades, demonstrating, the,...   \n",
       "1  [A, series, of, escapades, demonstrating, the,...   \n",
       "2                                        [A, series]   \n",
       "3                                                [A]   \n",
       "4                                           [series]   \n",
       "\n",
       "                                            pos_tags  \n",
       "0  [(A, DT), (series, NN), (of, IN), (escapades, ...  \n",
       "1  [(A, DT), (series, NN), (of, IN), (escapades, ...  \n",
       "2                            [(A, DT), (series, NN)]  \n",
       "3                                          [(A, DT)]  \n",
       "4                                     [(series, NN)]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pos_tags'] = df['tokens'].apply(pos_tag)\n",
    "\n",
    "df[['Phrase', 'tokens', 'pos_tags']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ee3162",
   "metadata": {},
   "source": [
    "## Stop Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "141107c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aarad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3292c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>[A, series, of, escapades, demonstrating, the,...</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>[A, series, of, escapades, demonstrating, the,...</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series</td>\n",
       "      <td>[A, series]</td>\n",
       "      <td>[series]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>[A]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[series]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Phrase  \\\n",
       "0  A series of escapades demonstrating the adage ...   \n",
       "1  A series of escapades demonstrating the adage ...   \n",
       "2                                           A series   \n",
       "3                                                  A   \n",
       "4                                             series   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [A, series, of, escapades, demonstrating, the,...   \n",
       "1  [A, series, of, escapades, demonstrating, the,...   \n",
       "2                                        [A, series]   \n",
       "3                                                [A]   \n",
       "4                                           [series]   \n",
       "\n",
       "                                 tokens_no_stopwords  \n",
       "0  [series, escapades, demonstrating, adage, good...  \n",
       "1  [series, escapades, demonstrating, adage, good...  \n",
       "2                                           [series]  \n",
       "3                                                 []  \n",
       "4                                           [series]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens_no_stopwords'] = df['tokens'].apply(lambda x: [word for word in x if word.lower() not in stopwords.words('english')])\n",
    "df[['Phrase', 'tokens', 'tokens_no_stopwords']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7314c7bc",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ce55da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>tokens_no_stopwords</th>\n",
       "      <th>stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "      <td>[seri, escapad, demonstr, adag, good, goos, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "      <td>[seri, escapad, demonstr, adag, good, goos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[seri]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[seri]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Phrase  \\\n",
       "0  A series of escapades demonstrating the adage ...   \n",
       "1  A series of escapades demonstrating the adage ...   \n",
       "2                                           A series   \n",
       "3                                                  A   \n",
       "4                                             series   \n",
       "\n",
       "                                 tokens_no_stopwords  \\\n",
       "0  [series, escapades, demonstrating, adage, good...   \n",
       "1  [series, escapades, demonstrating, adage, good...   \n",
       "2                                           [series]   \n",
       "3                                                 []   \n",
       "4                                           [series]   \n",
       "\n",
       "                                               stems  \n",
       "0  [seri, escapad, demonstr, adag, good, goos, al...  \n",
       "1        [seri, escapad, demonstr, adag, good, goos]  \n",
       "2                                             [seri]  \n",
       "3                                                 []  \n",
       "4                                             [seri]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "df['stems'] = df['tokens_no_stopwords'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "df[['Phrase', 'tokens_no_stopwords', 'stems']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd455d33",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25133e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aarad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\aarad\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29a60330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>tokens_no_stopwords</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "      <td>[series, escapade, demonstrating, adage, good,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "      <td>[series, escapade, demonstrating, adage, good,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[series]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[series]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Phrase  \\\n",
       "0  A series of escapades demonstrating the adage ...   \n",
       "1  A series of escapades demonstrating the adage ...   \n",
       "2                                           A series   \n",
       "3                                                  A   \n",
       "4                                             series   \n",
       "\n",
       "                                 tokens_no_stopwords  \\\n",
       "0  [series, escapades, demonstrating, adage, good...   \n",
       "1  [series, escapades, demonstrating, adage, good...   \n",
       "2                                           [series]   \n",
       "3                                                 []   \n",
       "4                                           [series]   \n",
       "\n",
       "                                              lemmas  \n",
       "0  [series, escapade, demonstrating, adage, good,...  \n",
       "1  [series, escapade, demonstrating, adage, good,...  \n",
       "2                                           [series]  \n",
       "3                                                 []  \n",
       "4                                           [series]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['lemmas'] = df['tokens_no_stopwords'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "df[['Phrase', 'tokens_no_stopwords', 'lemmas']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d7ea5",
   "metadata": {},
   "source": [
    "## TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43742be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29abd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['tokens_no_stopwords'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dffffc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (156060, 1000)\n",
      "Sample feature names: ['10' '20' '2002' '90' 'ability' 'able' 'across' 'act' 'acted' 'acting']\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "tfidf_matrix = tfidf.fit_transform(df['processed_text'])\n",
    "\n",
    "print(\"TF-IDF matrix shape:\", tfidf_matrix.shape)\n",
    "print(\"Sample feature names:\", tfidf.get_feature_names_out()[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239670d2",
   "metadata": {},
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7800c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c07b6a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5461040625400487\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.01      0.03      1416\n",
      "           1       0.50      0.08      0.14      5527\n",
      "           2       0.55      0.96      0.70     15639\n",
      "           3       0.53      0.21      0.30      6707\n",
      "           4       0.58      0.03      0.06      1923\n",
      "\n",
      "    accuracy                           0.55     31212\n",
      "   macro avg       0.58      0.26      0.25     31212\n",
      "weighted avg       0.55      0.55      0.45     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = tfidf_matrix\n",
    "y = df['Sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5efce5e",
   "metadata": {},
   "source": [
    "Here’s a concise theory for each step in your notebook:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Tokenization**\n",
    "**What:** Splitting text into individual words (tokens).  \n",
    "**Why:** Makes it easier to analyze and process text data at the word level for further NLP tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. POS Tagging**\n",
    "**What:** Assigning part-of-speech tags (noun, verb, adjective, etc.) to each token.  \n",
    "**Why:** Helps understand the grammatical structure and meaning of sentences, useful for advanced NLP tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Stop Words Removal**\n",
    "**What:** Removing common words like \"the\", \"is\", \"and\" that do not carry significant meaning.  \n",
    "**Why:** Reduces noise and focuses analysis on more meaningful words.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Stemming**\n",
    "**What:** Reducing words to their root form (e.g., \"playing\" → \"play\").  \n",
    "**Why:** Groups similar words together, improving the effectiveness of text analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Lemmatization**\n",
    "**What:** Converting words to their base or dictionary form (lemma), considering context.  \n",
    "**Why:** More accurate than stemming, helps in normalizing words for better analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. TF-IDF Calculation**\n",
    "**What:** Converts text into numerical features based on word importance (Term Frequency-Inverse Document Frequency).  \n",
    "**Why:** Represents text data in a way that can be used for machine learning models.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Text Classification**\n",
    "**What:** Using the processed features to train a machine learning model to predict sentiment.  \n",
    "**Why:** Automates the task of classifying text (e.g., positive/negative sentiment) based on learned patterns.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary:**  \n",
    "These steps transform raw text into structured, meaningful features suitable for machine learning, enabling automated text analysis and classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
